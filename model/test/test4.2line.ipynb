{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b056411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 패키지 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70ab880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    승하차_파일 = \"../../data/결과/승하차/통합/2호선_승하차인원_통합.csv\"\n",
    "    혼잡도_파일 = \"../../data/결과/혼잡도/통합/2호선_혼잡도_통합.csv\"\n",
    "    승하차_df = pd.read_csv(승하차_파일, encoding=\"euc-kr\")\n",
    "    혼잡도_df = pd.read_csv(혼잡도_파일, encoding=\"euc-kr\")\n",
    "    # 시간컬럼명 0패딩 통일\n",
    "    def fix_timecols(cols):\n",
    "        return [c if ':' not in c else c.zfill(5) for c in cols]\n",
    "    승하차_df.columns = fix_timecols(승하차_df.columns)\n",
    "    혼잡도_df.columns = fix_timecols(혼잡도_df.columns)\n",
    "    return 승하차_df, 혼잡도_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a046a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 승하차 데이터를 상행/하행으로 2배 복제\n",
    "def duplicate_for_directions(승하차):\n",
    "    dfs = []\n",
    "    for direction in [\"상행\", \"하행\"]:\n",
    "        tmp = 승하차.copy()\n",
    "        tmp['방향'] = direction\n",
    "        dfs.append(tmp)\n",
    "    return pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d670dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def standardize_columns(df, do_direction=True):\n",
    "    df[\"평일주말\"] = df[\"평일주말\"].astype(str).str.strip()\n",
    "    df[\"구분\"] = df[\"구분\"].astype(str).str.strip()\n",
    "    df[\"역번호\"] = df[\"역번호\"].astype(str).str.strip()\n",
    "    if do_direction and \"방향\" in df.columns:\n",
    "        df[\"방향\"] = df[\"방향\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d757a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. AI 딥러닝 학습 데이터 생성\n",
    "def build_dl_dataset(승하차, 혼잡도, 정원=2000):\n",
    "    rows = []\n",
    "    시간컬럼들 = [col for col in 승하차.columns if ':' in col]\n",
    "    fail, total = 0, 0\n",
    "    for idx, row in 승하차.iterrows():\n",
    "        for col in 시간컬럼들:\n",
    "            total += 1\n",
    "            hour = int(col.split(\":\")[0])\n",
    "            평일주말 = 1 if row[\"평일주말\"] == \"주말\" else 0\n",
    "            상행 = 1 if row[\"방향\"] == \"상행\" else 0\n",
    "            승차 = 1 if row[\"구분\"] == \"승차\" else 0\n",
    "            matched = 혼잡도[\n",
    "                (혼잡도[\"역번호\"].astype(str).str.strip() == row[\"역번호\"]) &\n",
    "                (혼잡도[\"평일주말\"].astype(str).str.strip() == row[\"평일주말\"]) &\n",
    "                (혼잡도[\"구분\"].astype(str).str.strip() == row[\"방향\"])\n",
    "            ]\n",
    "            if matched.empty or col not in 혼잡도.columns:\n",
    "                fail += 1\n",
    "                continue\n",
    "            try:\n",
    "                congestion = float(matched.iloc[0][col])\n",
    "                승하차인원 = float(row[col])\n",
    "            except Exception as e:\n",
    "                fail += 1\n",
    "                continue\n",
    "            y = int(congestion * 정원 / 100)\n",
    "            rows.append([\n",
    "                int(row[\"역번호\"]), hour, 평일주말, 상행, 승차, 승하차인원, congestion, y\n",
    "            ])\n",
    "    print(f\"> 학습데이터 생성: {len(rows)}행, 실패 {fail} / 총시도 {total}\")\n",
    "    cols = [\"역번호\", \"hour\", \"평일주말\", \"상행\", \"승차\", \"승하차인원\", \"혼잡도\", \"target\"]\n",
    "    return pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4a3224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 학습데이터 생성: 13016520행, 실패 131480 / 총시도 13148000\n",
      "   역번호  hour  평일주말  상행  승차  승하차인원   혼잡도  target\n",
      "0  201     5     1   1   1   39.0   5.2     104\n",
      "1  201     6     1   1   1   51.0   9.2     184\n",
      "2  201     7     1   1   1   95.0   9.9     198\n",
      "3  201     8     1   1   1  104.0  18.0     360\n",
      "4  201     9     1   1   1  129.0  21.0     420\n"
     ]
    }
   ],
   "source": [
    "# 6. 전체 파이프라인 (학습+예측)\n",
    "승하차, 혼잡도 = load_data()\n",
    "승하차_expanded = duplicate_for_directions(승하차)\n",
    "승하차_expanded = standardize_columns(승하차_expanded)\n",
    "혼잡도 = standardize_columns(혼잡도)\n",
    "df = build_dl_dataset(승하차_expanded, 혼잡도)\n",
    "print(df.head())\n",
    "if df.shape[0]==0:\n",
    "    raise ValueError(\"학습데이터 생성 실패! 컬럼 또는 값 일치 여부 확인 필요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4c489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 입력/정규화/트레인테스트 분리\n",
    "X = df[[\"역번호\", \"hour\", \"평일주말\", \"상행\", \"승차\", \"승하차인원\", \"혼잡도\"]].values\n",
    "y = df[\"target\"].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc40bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146436/146436 - 122s - 832us/step - loss: 137383.0000 - mae: 265.9721 - val_loss: 136610.6875 - val_mae: 265.1388\n",
      "Epoch 2/40\n",
      "146436/146436 - 122s - 835us/step - loss: 136507.9375 - mae: 265.1344 - val_loss: 136613.7344 - val_mae: 265.1971\n",
      "Epoch 3/40\n",
      "146436/146436 - 123s - 842us/step - loss: 136509.6719 - mae: 265.1288 - val_loss: 136609.1094 - val_mae: 264.7335\n",
      "Epoch 4/40\n",
      "146436/146436 - 123s - 841us/step - loss: 136507.6094 - mae: 265.1333 - val_loss: 136608.6250 - val_mae: 264.7450\n",
      "Epoch 5/40\n",
      "146436/146436 - 122s - 834us/step - loss: 136506.8906 - mae: 265.1308 - val_loss: 136606.8906 - val_mae: 264.7937\n",
      "Epoch 6/40\n",
      "146436/146436 - 123s - 843us/step - loss: 136507.7344 - mae: 265.1339 - val_loss: 136637.7812 - val_mae: 265.4820\n",
      "Epoch 7/40\n",
      "146436/146436 - 123s - 837us/step - loss: 136508.6250 - mae: 265.1330 - val_loss: 136636.8594 - val_mae: 264.4587\n",
      "Epoch 8/40\n",
      "146436/146436 - 123s - 843us/step - loss: 136509.7656 - mae: 265.1317 - val_loss: 136604.8125 - val_mae: 264.9417\n",
      "Epoch 9/40\n",
      "146436/146436 - 123s - 842us/step - loss: 136508.2969 - mae: 265.1316 - val_loss: 136605.2500 - val_mae: 264.8592\n",
      "Epoch 10/40\n",
      "146436/146436 - 124s - 846us/step - loss: 136507.4688 - mae: 265.1299 - val_loss: 136615.7500 - val_mae: 265.2273\n",
      "Epoch 11/40\n",
      "146436/146436 - 122s - 835us/step - loss: 136507.5469 - mae: 265.1313 - val_loss: 136607.3750 - val_mae: 264.7680\n",
      "Epoch 12/40\n",
      "146436/146436 - 123s - 841us/step - loss: 136509.2500 - mae: 265.1321 - val_loss: 136606.7031 - val_mae: 264.7831\n",
      "Epoch 13/40\n",
      "146436/146436 - 121s - 826us/step - loss: 136507.4219 - mae: 265.1350 - val_loss: 136735.2344 - val_mae: 264.0917\n",
      "Epoch 14/40\n",
      "146436/146436 - 119s - 816us/step - loss: 136506.9219 - mae: 265.1339 - val_loss: 136993.8125 - val_mae: 267.3273\n",
      "Epoch 15/40\n",
      "146436/146436 - 121s - 824us/step - loss: 136506.5781 - mae: 265.1344 - val_loss: 136679.2500 - val_mae: 264.2545\n",
      "Epoch 16/40\n",
      "146436/146436 - 117s - 797us/step - loss: 136508.2188 - mae: 265.1325 - val_loss: 136604.9844 - val_mae: 264.9721\n",
      "Epoch 17/40\n",
      "146436/146436 - 115s - 783us/step - loss: 136507.8125 - mae: 265.1295 - val_loss: 136651.8438 - val_mae: 265.6029\n",
      "Epoch 18/40\n",
      "146436/146436 - 116s - 793us/step - loss: 136508.8438 - mae: 265.1317 - val_loss: 136607.0469 - val_mae: 264.7817\n",
      "Epoch 19/40\n",
      "146436/146436 - 115s - 787us/step - loss: 136507.7812 - mae: 265.1320 - val_loss: 136608.6875 - val_mae: 265.1018\n",
      "Epoch 20/40\n",
      "146436/146436 - 117s - 798us/step - loss: 136507.1094 - mae: 265.1329 - val_loss: 136606.2812 - val_mae: 265.0264\n",
      "Epoch 21/40\n",
      "146436/146436 - 116s - 793us/step - loss: 136508.4375 - mae: 265.1343 - val_loss: 136719.0781 - val_mae: 264.1330\n",
      "Epoch 22/40\n",
      "146436/146436 - 116s - 789us/step - loss: 136507.1406 - mae: 265.1333 - val_loss: 136661.4844 - val_mae: 264.3289\n",
      "Epoch 23/40\n",
      "146436/146436 - 116s - 793us/step - loss: 136507.3438 - mae: 265.1319 - val_loss: 136606.8750 - val_mae: 264.7937\n",
      "Epoch 24/40\n",
      "146436/146436 - 116s - 791us/step - loss: 136505.3125 - mae: 265.1287 - val_loss: 136651.4531 - val_mae: 265.5985\n",
      "Epoch 25/40\n",
      "146436/146436 - 116s - 795us/step - loss: 136507.7344 - mae: 265.1350 - val_loss: 136618.7031 - val_mae: 264.6057\n",
      "Epoch 26/40\n",
      "146436/146436 - 117s - 798us/step - loss: 136508.5469 - mae: 265.1327 - val_loss: 136652.3750 - val_mae: 264.3686\n",
      "Epoch 27/40\n",
      "146436/146436 - 117s - 798us/step - loss: 136505.8906 - mae: 265.1295 - val_loss: 136605.8750 - val_mae: 265.0145\n",
      "Epoch 28/40\n",
      "146436/146436 - 117s - 797us/step - loss: 136505.6406 - mae: 265.1288 - val_loss: 136623.2656 - val_mae: 264.5659\n",
      "Epoch 29/40\n",
      "146436/146436 - 117s - 800us/step - loss: 136505.7344 - mae: 265.1297 - val_loss: 136609.0781 - val_mae: 265.1129\n",
      "Epoch 30/40\n",
      "146436/146436 - 117s - 796us/step - loss: 136504.1719 - mae: 265.1300 - val_loss: 136645.7031 - val_mae: 264.4065\n",
      "Epoch 31/40\n",
      "146436/146436 - 116s - 790us/step - loss: 136505.9688 - mae: 265.1324 - val_loss: 136638.8750 - val_mae: 265.4931\n",
      "Epoch 32/40\n",
      "146436/146436 - 116s - 792us/step - loss: 136504.4062 - mae: 265.1322 - val_loss: 136628.7500 - val_mae: 264.5171\n",
      "Epoch 33/40\n",
      "146436/146436 - 117s - 796us/step - loss: 136506.7031 - mae: 265.1310 - val_loss: 136727.3594 - val_mae: 264.1068\n",
      "Epoch 34/40\n",
      "146436/146436 - 116s - 791us/step - loss: 136506.3438 - mae: 265.1288 - val_loss: 136656.2812 - val_mae: 265.6395\n",
      "Epoch 35/40\n",
      "146436/146436 - 116s - 795us/step - loss: 136506.1406 - mae: 265.1262 - val_loss: 136604.8125 - val_mae: 264.9378\n",
      "Epoch 36/40\n",
      "146436/146436 - 116s - 793us/step - loss: 136506.3125 - mae: 265.1299 - val_loss: 136625.2188 - val_mae: 264.5402\n",
      "Epoch 37/40\n",
      "146436/146436 - 118s - 808us/step - loss: 136505.9375 - mae: 265.1294 - val_loss: 136606.8906 - val_mae: 264.7958\n",
      "Epoch 38/40\n",
      "146436/146436 - 156s - 1ms/step - loss: 136507.5000 - mae: 265.1298 - val_loss: 136604.9062 - val_mae: 264.8760\n",
      "Epoch 39/40\n",
      "146436/146436 - 131s - 893us/step - loss: 136504.5469 - mae: 265.1277 - val_loss: 136632.0469 - val_mae: 265.4307\n",
      "Epoch 40/40\n",
      "146436/146436 - 117s - 802us/step - loss: 136505.7812 - mae: 265.1268 - val_loss: 136667.5938 - val_mae: 265.7372\n"
     ]
    }
   ],
   "source": [
    "# 8. 딥러닝 모델 정의&학습\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1644c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['my_scaler.2line.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 직후 (fit 다음 셀)\n",
    "model.save(\"my_dl_model.2line.h5\")\n",
    "import joblib\n",
    "joblib.dump(scaler, \"my_scaler.2line.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d10366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 예측 함수\n",
    "def dl_predict(역번호, hour, 평일주말, 상행, 승차, 승하차인원, 혼잡도):\n",
    "    arr = np.array([[역번호, hour, 평일주말, 상행, 승차, 승하차인원, 혼잡도]])\n",
    "    arr_scaled = scaler.transform(arr)\n",
    "    pred = model.predict(arr_scaled)\n",
    "    return int(pred[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "663345cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_predict_smart():\n",
    "    # 입력\n",
    "    역명 = input(\"역명: \")\n",
    "    호선 = input(\"호선: \")\n",
    "    방향 = input(\"방향 (상행/하행): \").strip()\n",
    "    평일주말_str = input(\"요일 (평일/주말): \").strip()\n",
    "    시간 = input(\"시간 (HH:MM): \").strip()\n",
    "\n",
    "    # 시간 가공\n",
    "    hour = int(시간.split(\":\")[0])\n",
    "    평일주말 = 1 if 평일주말_str == \"주말\" else 0\n",
    "    상행 = 1 if 방향 == \"상행\" else 0\n",
    "\n",
    "    # 역번호 자동 조회\n",
    "    # 최신화 : 승하차/혼잡도 둘 다에 맞추려면 승하차 or 혼잡도 데이터(ex. 승하차_expanded)에서 조회\n",
    "    # 보통 승하차 데이터에 역명, 호선이 있으므로:\n",
    "    df_ref = 승하차_expanded\n",
    "    후보 = df_ref[(df_ref[\"역명\"] == 역명) & (df_ref[\"호선\"].astype(str) == str(호선))]\n",
    "    if 후보.empty:\n",
    "        print(f\"해당 역명/호선이 데이터에 없습니다.\")\n",
    "        return\n",
    "    역번호 = int(후보.iloc[0][\"역번호\"])\n",
    "\n",
    "    # 승하차 값 탐색\n",
    "    row_승 = df_ref[\n",
    "        (df_ref[\"역번호\"] == str(역번호)) &\n",
    "        (df_ref[\"방향\"] == 방향) &\n",
    "        (df_ref[\"평일주말\"] == 평일주말_str) &\n",
    "        (df_ref[\"구분\"] == \"승차\")\n",
    "    ]\n",
    "    row_하 = df_ref[\n",
    "        (df_ref[\"역번호\"] == str(역번호)) &\n",
    "        (df_ref[\"방향\"] == 방향) &\n",
    "        (df_ref[\"평일주말\"] == 평일주말_str) &\n",
    "        (df_ref[\"구분\"] == \"하차\")\n",
    "    ]\n",
    "    시간컬럼 = 시간 if 시간 in df_ref.columns else f\"{hour:02d}:00\"\n",
    "    # 승차/하차 인원 조회(둘 다 있는 경우 합쳐도 되고, 하나만 써도 됨)\n",
    "    if not row_승.empty and 시간컬럼 in row_승.columns:\n",
    "        승차인원 = float(row_승.iloc[0][시간컬럼])\n",
    "    else:\n",
    "        승차인원 = 0\n",
    "    if not row_하.empty and 시간컬럼 in row_하.columns:\n",
    "        하차인원 = float(row_하.iloc[0][시간컬럼])\n",
    "    else:\n",
    "        하차인원 = 0\n",
    "    승하차인원 = 승차인원 + 하차인원 # 혹은 필요에 따라 방법 선택\n",
    "\n",
    "    # 혼잡도 탐색\n",
    "    row_혼 = 혼잡도[\n",
    "        (혼잡도[\"역번호\"] == str(역번호)) &\n",
    "        (혼잡도[\"구분\"] == 방향) &\n",
    "        (혼잡도[\"평일주말\"] == 평일주말_str)\n",
    "    ]\n",
    "    if not row_혼.empty and 시간컬럼 in row_혼.columns:\n",
    "        혼잡도_val = float(row_혼.iloc[0][시간컬럼])\n",
    "    else:\n",
    "        혼잡도_val = 0\n",
    "\n",
    "    # 예측\n",
    "    pred = dl_predict(\n",
    "        역번호=역번호,\n",
    "        hour=hour,\n",
    "        평일주말=평일주말,\n",
    "        상행=상행,\n",
    "        승차=1,  # 승차만 예측할지, 승/하차인원합 예측할지는 논리 선택!\n",
    "        승하차인원=승하차인원,\n",
    "        혼잡도=혼잡도_val\n",
    "    )\n",
    "\n",
    "    # 출력\n",
    "    print(f\"예측: {호선}호선 {역명}({역번호}) {방향} {평일주말_str} {시간}\")\n",
    "    print(f\"  승하차 인원(입력값): {승하차인원}, 혼잡도(%): {혼잡도_val:.1f}\")\n",
    "    print(f\"  딥러닝 기반 예측 열차 내 인원: {pred} 명\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c0195d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 실행 예시\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43muser_predict_smart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m, in \u001b[0;36muser_predict_smart\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m 시간 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m시간 (HH:MM): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 시간 가공\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m hour \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m시간\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m 평일주말 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m 평일주말_str \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m주말\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m 상행 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m 방향 \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m상행\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# 실행 예시\n",
    "user_predict_smart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b72909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1704178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
