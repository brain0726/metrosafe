{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2023b9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b72909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 패키지 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1704178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 파일 경로 및 주요 파라미터 별도 선언\n",
    "승하차_파일 = \"../../data/결과/승하차/통합/6호선_승하차인원_통합.csv\"\n",
    "혼잡도_파일 = \"../../data/결과/혼잡도/통합/6호선_혼잡도_통합.csv\"\n",
    "정원 = 2000  # 열차 정원\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fdc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 불러오기 및 0패딩 맞춤\n",
    "def fix_timecols(cols):\n",
    "    return [c if \":\" not in c else c.zfill(5) for c in cols]\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    승하차_df = pd.read_csv(승하차_파일, encoding=\"euc-kr\")\n",
    "    혼잡도_df = pd.read_csv(혼잡도_파일, encoding=\"euc-kr\")\n",
    "    승하차_df.columns = fix_timecols(승하차_df.columns)\n",
    "    혼잡도_df.columns = fix_timecols(혼잡도_df.columns)\n",
    "    return 승하차_df, 혼잡도_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ea49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 상행/하행 방향 데이터 복제\n",
    "def duplicate_for_directions(승하차):\n",
    "    dfs = []\n",
    "    for direction in [\"상행\", \"하행\"]:\n",
    "        tmp = 승하차.copy()\n",
    "        tmp[\"방향\"] = direction\n",
    "        dfs.append(tmp)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa88cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 컬럼 표준화\n",
    "def standardize_columns(df, do_direction=True):\n",
    "    df[\"평일주말\"] = df[\"평일주말\"].astype(str).str.strip()\n",
    "    df[\"구분\"] = df[\"구분\"].astype(str).str.strip()\n",
    "    df[\"역번호\"] = df[\"역번호\"].astype(str).str.strip()\n",
    "    if do_direction and \"방향\" in df.columns:\n",
    "        df[\"방향\"] = df[\"방향\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ede7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. 벡터 연산 기반 학습 데이터 생성\n",
    "def build_dl_dataset(승하차, 혼잡도, 정원=2000):\n",
    "    시간컬럼들 = [col for col in 승하차.columns if \":\" in col]\n",
    "    # key 조합 만들기\n",
    "    승하차[\"key\"] = (\n",
    "        승하차[\"역번호\"].astype(str)\n",
    "        + \"_\"\n",
    "        + 승하차[\"방향\"].astype(str)\n",
    "        + \"_\"\n",
    "        + 승하차[\"평일주말\"].astype(str)\n",
    "    )\n",
    "    혼잡도[\"key\"] = (\n",
    "        혼잡도[\"역번호\"].astype(str)\n",
    "        + \"_\"\n",
    "        + 혼잡도[\"구분\"].astype(str)\n",
    "        + \"_\"\n",
    "        + 혼잡도[\"평일주말\"].astype(str)\n",
    "    )\n",
    "    # 혼잡도에서 필요한 시간만 추출 후 melt\n",
    "    혼잡도_long = 혼잡도.melt(\n",
    "        id_vars=[\"key\"], value_vars=시간컬럼들, var_name=\"time\", value_name=\"혼잡도\"\n",
    "    )\n",
    "    승하차_long = 승하차.melt(\n",
    "        id_vars=[\"key\", \"역번호\", \"방향\", \"평일주말\", \"구분\"],\n",
    "        value_vars=시간컬럼들,\n",
    "        var_name=\"time\",\n",
    "        value_name=\"승하차인원\",\n",
    "    )\n",
    "    # merge\n",
    "    merged = pd.merge(승하차_long, 혼잡도_long, on=[\"key\", \"time\"], how=\"inner\")\n",
    "    # feature 생성\n",
    "    merged[\"hour\"] = merged[\"time\"].str.split(\":\").str[0].astype(int)\n",
    "    merged[\"평일주말_digit\"] = merged[\"평일주말\"].map({\"평일\": 0, \"주말\": 1})\n",
    "    merged[\"상행\"] = (merged[\"방향\"] == \"상행\").astype(int)\n",
    "    merged[\"승차\"] = (merged[\"구분\"] == \"승차\").astype(int)\n",
    "    merged[\"혼잡도\"] = pd.to_numeric(merged[\"혼잡도\"], errors=\"coerce\").fillna(0)\n",
    "    merged[\"승하차인원\"] = pd.to_numeric(merged[\"승하차인원\"], errors=\"coerce\").fillna(\n",
    "        0\n",
    "    )\n",
    "    merged[\"target\"] = (merged[\"혼잡도\"] * 정원 / 100).astype(int)\n",
    "    cols = [\n",
    "        \"역번호\",\n",
    "        \"hour\",\n",
    "        \"평일주말_digit\",\n",
    "        \"상행\",\n",
    "        \"승차\",\n",
    "        \"승하차인원\",\n",
    "        \"혼잡도\",\n",
    "        \"target\",\n",
    "    ]\n",
    "    merged = merged[cols].dropna().reset_index(drop=True)\n",
    "    merged[\"역번호\"] = merged[\"역번호\"].astype(int)\n",
    "    return merged\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e058d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 입력 값 안전하게 받는 함수\n",
    "def safe_hour_input():\n",
    "    while True:\n",
    "        s = input(\"시간 (HH:MM): \").strip()\n",
    "        parts = s.split(\":\")\n",
    "        if len(parts) == 2 and parts[0].isdigit():\n",
    "            return int(parts[0]), f\"{int(parts[0]):02d}:00\"\n",
    "        print(\"시간을 올바른 형식(HH:MM)으로 입력하세요.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbb0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 사용자 예측 함수 개선\n",
    "def user_predict_smart(승하차_df, 혼잡도_df, scaler, model):\n",
    "    역명 = input(\"역명: \").strip()\n",
    "    호선 = input(\"호선: \").strip()\n",
    "    방향 = input(\"방향 (상행/하행): \").strip()\n",
    "    평일주말_str = input(\"요일 (평일/주말): \").strip()\n",
    "    hour, 시간컬럼 = safe_hour_input()\n",
    "    평일주말 = 1 if 평일주말_str == \"주말\" else 0\n",
    "    상행 = 1 if 방향 == \"상행\" else 0\n",
    "\n",
    "    # 역번호 찾기\n",
    "    후보 = 승하차_df[\n",
    "        (승하차_df[\"역명\"] == 역명) & (승하차_df[\"호선\"].astype(str) == str(호선))\n",
    "    ]\n",
    "    if 후보.empty:\n",
    "        print(f\"해당 역명/호선이 데이터에 없습니다.\")\n",
    "        return\n",
    "    역번호 = int(후보.iloc[0][\"역번호\"])\n",
    "\n",
    "    # 승차/하차 인원 찾기\n",
    "    def get_people(df, 구분):\n",
    "        row = df[\n",
    "            (df[\"역번호\"] == str(역번호))\n",
    "            & (df[\"방향\"] == 방향)\n",
    "            & (df[\"평일주말\"] == 평일주말_str)\n",
    "            & (df[\"구분\"] == 구분)\n",
    "        ]\n",
    "        if not row.empty and 시간컬럼 in row.columns:\n",
    "            try:\n",
    "                return float(row.iloc[0][시간컬럼])\n",
    "            except Exception:\n",
    "                return 0\n",
    "        return 0\n",
    "\n",
    "    승차인원 = get_people(승하차_df, \"승차\")\n",
    "    하차인원 = get_people(승하차_df, \"하차\")\n",
    "    승하차인원 = 승차인원 + 하차인원\n",
    "\n",
    "    # 혼잡도 찾기\n",
    "    row_혼 = 혼잡도_df[\n",
    "        (혼잡도_df[\"역번호\"] == str(역번호))\n",
    "        & (혼잡도_df[\"구분\"] == 방향)\n",
    "        & (혼잡도_df[\"평일주말\"] == 평일주말_str)\n",
    "    ]\n",
    "    혼잡도_val = 0\n",
    "    if not row_혼.empty and 시간컬럼 in row_혼.columns:\n",
    "        try:\n",
    "            혼잡도_val = float(row_혼.iloc[0][시간컬럼])\n",
    "        except Exception:\n",
    "            혼잡도_val = 0\n",
    "\n",
    "    # 예측\n",
    "    arr = np.array([[역번호, hour, 평일주말, 상행, 1, 승하차인원, 혼잡도_val]])\n",
    "    arr_scaled = scaler.transform(arr)\n",
    "    pred = model.predict(arr_scaled, verbose=0)\n",
    "    print(f\"예측: {호선}호선 {역명}({역번호}) {방향} {평일주말_str} {시간컬럼}\")\n",
    "    print(f\" 승하차 인원(입력): {승하차인원}, 혼잡도(%): {혼잡도_val:.1f}\")\n",
    "    print(f\" 딥러닝 기반 예측 열차 내 인원: {int(pred[0][0])} 명\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11044873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 데이터 로딩 및 전처리...\n",
      "> 학습데이터 shape: (17560800, 8)\n"
     ]
    }
   ],
   "source": [
    "# 9. 전체 데이터 전처리 및 학습\n",
    "\n",
    "print(\"> 데이터 로딩 및 전처리...\")\n",
    "승하차, 혼잡도 = load_data()\n",
    "승하차_expanded = duplicate_for_directions(승하차)\n",
    "승하차_expanded = standardize_columns(승하차_expanded)\n",
    "혼잡도 = standardize_columns(혼잡도)\n",
    "df = build_dl_dataset(승하차_expanded, 혼잡도, 정원=정원)\n",
    "if df.shape[0] == 0:\n",
    "    raise ValueError(\"학습데이터 생성 실패! 컬럼 또는 값 일치 여부 확인 필요.\")\n",
    "print(f\"> 학습데이터 shape: {df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083ad1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 입력/정규화/트레인테스트 분리\n",
    "X = df[\n",
    "    [\"역번호\", \"hour\", \"평일주말_digit\", \"상행\", \"승차\", \"승하차인원\", \"혼잡도\"]\n",
    "].values\n",
    "y = df[\"target\"].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "197559/197559 - 372s - 2ms/step - loss: 192.9494 - mae: 0.9911 - val_loss: 0.0886 - val_mae: 0.2428\n",
      "Epoch 2/40\n",
      "197559/197559 - 1046s - 5ms/step - loss: 0.3546 - mae: 0.3253 - val_loss: 0.0100 - val_mae: 0.0718\n",
      "Epoch 3/40\n",
      "197559/197559 - 585s - 3ms/step - loss: 0.2658 - mae: 0.2757 - val_loss: 0.0099 - val_mae: 0.0711\n",
      "Epoch 4/40\n",
      "197559/197559 - 936s - 5ms/step - loss: 0.2214 - mae: 0.2431 - val_loss: 0.0145 - val_mae: 0.0886\n",
      "Epoch 5/40\n",
      "197559/197559 - 241s - 1ms/step - loss: 0.1981 - mae: 0.2193 - val_loss: 0.0575 - val_mae: 0.2017\n",
      "Epoch 6/40\n",
      "197559/197559 - 474s - 2ms/step - loss: 0.1628 - mae: 0.1998 - val_loss: 0.0058 - val_mae: 0.0520\n",
      "Epoch 7/40\n",
      "197559/197559 - 404s - 2ms/step - loss: 0.1464 - mae: 0.1854 - val_loss: 0.0240 - val_mae: 0.0906\n",
      "Epoch 8/40\n",
      "197559/197559 - 230s - 1ms/step - loss: 0.1326 - mae: 0.1778 - val_loss: 0.0051 - val_mae: 0.0396\n",
      "Epoch 9/40\n",
      "197559/197559 - 236s - 1ms/step - loss: 0.1234 - mae: 0.1728 - val_loss: 0.0080 - val_mae: 0.0570\n",
      "Epoch 10/40\n",
      "197559/197559 - 237s - 1ms/step - loss: 0.1122 - mae: 0.1690 - val_loss: 0.0093 - val_mae: 0.0698\n",
      "Epoch 11/40\n",
      "197559/197559 - 224s - 1ms/step - loss: 0.1082 - mae: 0.1626 - val_loss: 0.0079 - val_mae: 0.0603\n",
      "Epoch 12/40\n",
      "197559/197559 - 232s - 1ms/step - loss: 0.1052 - mae: 0.1581 - val_loss: 0.0047 - val_mae: 0.0401\n",
      "Epoch 13/40\n"
     ]
    }
   ],
   "source": [
    "# 11. 딥러닝 모델과 학습 (Input 경고 해결 및 EarlyStopping 추가)\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(X_train.shape[1],)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319cfe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 모델/스케일러 저장 (최신 포맷)\n",
    "model.save(\"my_dl_model.6line.keras\")\n",
    "joblib.dump(scaler, \"my_scaler.6line.pkl\")\n",
    "\n",
    "# 13. 예측 예제 실행\n",
    "# user_predict_smart(승하차_expanded, 혼잡도, scaler, model)   # ← 실제 실행 시 활성화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
