{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc7968fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "승하차_파일 = \"../../data/결과/승하차/통합/1호선_승하차인원_통합.csv\"\n",
    "혼잡도_파일 = \"../../data/결과/혼잡도/통합/1호선_혼잡도_통합.csv\"\n",
    "시간표_파일 = \"../../data/결과/운행시간표/통합/1호선_열차운행시각표.csv\"\n",
    "\n",
    "승하차_df = pd.read_csv(승하차_파일, encoding=\"euc-kr\")\n",
    "혼잡도_df = pd.read_csv(혼잡도_파일, encoding=\"euc-kr\")\n",
    "시간표_df = pd.read_csv(시간표_파일, encoding=\"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f0b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols = [col for col in 승하차_df.columns if \":\" in col]\n",
    "# 분석 대상 설정\n",
    "target_station = \"서울역\"  # 또는 다른 역명\n",
    "target_daytype = \"평일\"  # 또는 \"주말\"\n",
    "\n",
    "# 승차 데이터 long 형식\n",
    "승차_long = pd.melt(\n",
    "    승하차_df[\n",
    "        (승하차_df[\"구분\"] == \"승차\")\n",
    "        & (승하차_df[\"역명\"] == target_station)\n",
    "        & (승하차_df[\"평일주말\"] == target_daytype)\n",
    "    ],\n",
    "    id_vars=[\"평일주말\", \"호선\", \"역번호\", \"역명\"],\n",
    "    value_vars=time_cols,\n",
    "    var_name=\"시간\",\n",
    "    value_name=\"승차인원\",\n",
    ")\n",
    "\n",
    "# 하차 데이터 long 형식\n",
    "하차_long = pd.melt(\n",
    "    승하차_df[\n",
    "        (승하차_df[\"구분\"] == \"하차\")\n",
    "        & (승하차_df[\"역명\"] == target_station)\n",
    "        & (승하차_df[\"평일주말\"] == target_daytype)\n",
    "    ],\n",
    "    id_vars=[\"평일주말\", \"호선\", \"역번호\", \"역명\"],\n",
    "    value_vars=time_cols,\n",
    "    var_name=\"시간\",\n",
    "    value_name=\"하차인원\",\n",
    ")\n",
    "\n",
    "# 혼잡도 데이터 long 형식 (상행만 사용)\n",
    "혼잡도_long = pd.melt(\n",
    "    혼잡도_df[\n",
    "        (혼잡도_df[\"역명\"] == target_station)\n",
    "        & (혼잡도_df[\"평일주말\"] == target_daytype)\n",
    "        & (혼잡도_df[\"구분\"] == \"상행\")\n",
    "    ],\n",
    "    id_vars=[\"평일주말\", \"호선\", \"역번호\", \"역명\", \"구분\"],\n",
    "    value_vars=time_cols,\n",
    "    var_name=\"시간\",\n",
    "    value_name=\"혼잡도\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8d149d",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.18 GiB for an array with shape (695581740,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m merge_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m      3\u001b[0m     승차_long, 하차_long, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m평일주말\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m호선\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m역번호\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m역명\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m시간\u001b[39m\u001b[38;5;124m\"\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 혼잡도 추가 병합 (구분 컬럼 제거)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m      8\u001b[0m     merge_df,\n\u001b[0;32m      9\u001b[0m     혼잡도_long\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m구분\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     10\u001b[0m     on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m평일주말\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m호선\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m역번호\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m역명\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m시간\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     11\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 시간순 정렬을 위한 정수형 시간 컬럼 추가\u001b[39;00m\n\u001b[0;32m     15\u001b[0m final_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m시간_int\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m final_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m시간\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:886\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1151\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1148\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1151\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_indexers()\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1125\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_join_indexers(\n\u001b[0;32m   1126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow\n\u001b[0;32m   1127\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1759\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     _, lidx, ridx \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mjoin(right, how\u001b[38;5;241m=\u001b[39mhow, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1759\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m get_join_indexers_non_unique(\n\u001b[0;32m   1760\u001b[0m         left\u001b[38;5;241m.\u001b[39m_values, right\u001b[38;5;241m.\u001b[39m_values, sort, how\n\u001b[0;32m   1761\u001b[0m     )\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(lidx, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m   1764\u001b[0m     lidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1795\u001b[0m, in \u001b[0;36mget_join_indexers_non_unique\u001b[1;34m(left, right, sort, how)\u001b[0m\n\u001b[0;32m   1793\u001b[0m lkey, rkey, count \u001b[38;5;241m=\u001b[39m _factorize_keys(left, right, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1795\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join(lkey, rkey, count, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1797\u001b[0m     ridx, lidx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join(rkey, lkey, count, sort\u001b[38;5;241m=\u001b[39msort)\n",
      "File \u001b[1;32mjoin.pyx:156\u001b[0m, in \u001b[0;36mpandas._libs.join.left_outer_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.18 GiB for an array with shape (695581740,) and data type int64"
     ]
    }
   ],
   "source": [
    "# 승차 + 하차 데이터 병합\n",
    "merge_df = pd.merge(\n",
    "    승차_long, 하차_long, on=[\"평일주말\", \"호선\", \"역번호\", \"역명\", \"시간\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "# 혼잡도 추가 병합 (구분 컬럼 제거)\n",
    "final_df = pd.merge(\n",
    "    merge_df,\n",
    "    혼잡도_long.drop(\"구분\", axis=1),\n",
    "    on=[\"평일주말\", \"호선\", \"역번호\", \"역명\", \"시간\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# 시간순 정렬을 위한 정수형 시간 컬럼 추가\n",
    "final_df[\"시간_int\"] = final_df[\"시간\"].apply(lambda x: int(x.split(\":\")[0]))\n",
    "final_df = final_df.sort_values(\"시간_int\").reset_index(drop=True)\n",
    "\n",
    "# 결과 미리 확인\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_day_df(역명, 평일주말, 승차_long, 하차_long, 혼잡도_long):\n",
    "    # 미리 필터링\n",
    "    승차 = 승차_long[(승차_long[\"역명\"] == 역명) & (승차_long[\"평일주말\"] == 평일주말)]\n",
    "    하차 = 하차_long[(하차_long[\"역명\"] == 역명) & (하차_long[\"평일주말\"] == 평일주말)]\n",
    "    혼잡도 = 혼잡도_long[\n",
    "        (혼잡도_long[\"역명\"] == 역명)\n",
    "        & (혼잡도_long[\"평일주말\"] == 평일주말)\n",
    "        & (혼잡도_long[\"구분\"] == \"상행\")\n",
    "    ]\n",
    "    # 병합\n",
    "    merge_df = pd.merge(\n",
    "        승차, 하차, on=[\"평일주말\", \"호선\", \"역번호\", \"역명\", \"시간\"], how=\"inner\"\n",
    "    )\n",
    "    final_df = pd.merge(\n",
    "        merge_df,\n",
    "        혼잡도.drop(\"구분\", axis=1),\n",
    "        on=[\"평일주말\", \"호선\", \"역번호\", \"역명\", \"시간\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    return final_df\n",
    "\n",
    "\n",
    "# 사용 예:\n",
    "# result_df = get_station_day_df('서울역', '평일', 승차_long, 하차_long, 혼잡도_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = final_df[[\"승차인원\", \"하차인원\", \"혼잡도\"]].fillna(0).values\n",
    "target = final_df[\"승차인원\"].values  # 예시로 승차인원 예측, 필요시 혼잡도 등으로 대체\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd56608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, target, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i : i + seq_length])\n",
    "        ys.append(target[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "SEQ_LEN = 4\n",
    "X, y = create_sequences(features_scaled, target, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e23105",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [LSTM(16, input_shape=(SEQ_LEN, X.shape[2])), Dense(8, activation=\"relu\"), Dense(1)]\n",
    ")\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X, y, epochs=60, batch_size=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d760dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_station_passenger(model, scaler, df, input_time, seq_len=4):\n",
    "    # 시간 매칭: 입력값 (예: '13:00')에 가장 가까운 시간 결정\n",
    "    df = df.sort_values(\"시간_int\").reset_index(drop=True)\n",
    "    # 입력된 시간의 인덱스(정확히 없으면 이전 시간 사용)\n",
    "    시간_int = int(input_time.split(\":\")[0])\n",
    "    idx = df[df[\"시간_int\"] == 시간_int].index\n",
    "    if len(idx) == 0 or idx[0] < seq_len:\n",
    "        return \"초기 구간은 예측 불가\"\n",
    "    idx = idx[0]\n",
    "    x_input = df[[\"승차인원\", \"하차인원\", \"혼잡도\"]].fillna(0).values\n",
    "    x_input = scaler.transform(x_input)\n",
    "    x_input = x_input[idx - seq_len : idx].reshape(1, seq_len, 3)\n",
    "    pred = model.predict(x_input)\n",
    "    return f\"{input_time} 기준 예상 승차인원: {int(pred[0,0])}명\"\n",
    "\n",
    "\n",
    "# 예시 실행\n",
    "print(predict_station_passenger(model, scaler, final_df, \"7:00\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
